{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "def vectorizeImage(image_path):\n",
    "    # Abre la imagen y la convierte en un vector\n",
    "    image = Image.open(image_path)\n",
    "    # Opcional: Redimensionar o convertir a escala de grises si es necesario\n",
    "    # image = image.resize((ancho_deseado, alto_deseado))\n",
    "    # image = image.convert('L')  # Para escala de grises\n",
    "    return np.array(image).flatten().astype(np.uint8)\n",
    "def splitDataFrames(df_train,df_test,n_train,n_test,random_state=42,proporcion_positiva=0.1,label_col='class_num'):\n",
    "    # Dividir los dataframes en train y test\n",
    "    n_positivos = int(n_train*proporcion_positiva)\n",
    "    n_negativos = n_train-n_positivos\n",
    "    df_train_positivo = df_train[df_train[label_col]==1]\n",
    "    df_train_negativo = df_train[df_train[label_col]==0]\n",
    "    df_test_positivo = df_test[df_test[label_col]==1]\n",
    "    df_test_negativo = df_test[df_test[label_col]==0]\n",
    "    # Dividir los dataframes en train y test\n",
    "    df_train_positivo = df_train_positivo.sample(n=n_positivos,random_state=random_state)\n",
    "    df_train_negativo = df_train_negativo.sample(n=n_negativos,random_state=random_state)\n",
    "    n_positivos = int(n_test*proporcion_positiva)\n",
    "    n_negativos = n_test-n_positivos\n",
    "    df_test_positivo = df_test_positivo.sample(n=n_positivos,random_state=random_state)\n",
    "    df_test_negativo = df_test_negativo.sample(n=n_negativos,random_state=random_state)\n",
    "    # Concatenar los dataframes\n",
    "    df_train = pd.concat([df_train_positivo,df_train_negativo],ignore_index=True)\n",
    "    df_test = pd.concat([df_test_positivo,df_test_negativo],ignore_index=True)\n",
    "    return df_train,df_test\n",
    "\n",
    "df_train = pd.read_csv('../../datasets/covid/datos_redimensionados_entrenamiento.txt',sep=' ')\n",
    "df_test = pd.read_csv('../../datasets/covid/datos_redimensionados_prueba.txt',sep=' ')\n",
    "df_train['class_num'] = df_train['class'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "df_test['class_num'] = df_test['class'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "N = 1000\n",
    "N_TEST = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([vectorizeImage(file) for file in df_entrenamiento['path_redimensionada'].values])\n",
    "X_train.shape\n",
    "y_train = df_entrenamiento['class_num'].values\n",
    "X_test = np.array([vectorizeImage(file) for file in df_prueba['path_redimensionada'].values])\n",
    "y_test = df_prueba['class_num'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_positiva = df_entrenamiento[df_entrenamiento['class_num'] == 1].shape[0] / df_entrenamiento.shape[0]\n",
    "p_negativa = df_entrenamiento[df_entrenamiento['class_num'] == 0].shape[0] / df_entrenamiento.shape[0]\n",
    "print(p_positiva, p_negativa)\n",
    "p_prueba_positiva = df_prueba[df_prueba['class_num'] == 1].shape[0] / df_prueba.shape[0]\n",
    "p_prueba_negativa = df_prueba[df_prueba['class_num'] == 0].shape[0] / df_prueba.shape[0]\n",
    "print(p_prueba_positiva, p_prueba_negativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('memoria ocupada por X_train:', X_train.nbytes / 1024 / 1024, 'MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# km = KMeans(n_clusters=2)\n",
    "# km.fit(X_train)\n",
    "# y_pred_test = km.predict(X_test)\n",
    "# a = accuracy_score(y_test, y_pred_test)\n",
    "# print('Accuracy:', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# cm = confusion_matrix(y_test, y_pred_test)\n",
    "# print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exactitudes = []\n",
    "# proporciones = []\n",
    "# for x in np.linspace(0.001,0.01,10):\n",
    "#     df_e,df_t = splitDataFrames(df_train,df_test,N,N_test,proporcion_positiva=x,random_state=0)\n",
    "#     X_train = np.array([vectorizeImage(file) for file in df_e['path_redimensionada'].values])\n",
    "#     y_train = df_e['class_num'].values\n",
    "#     km = KMeans(n_clusters=2)\n",
    "#     km.fit(X_train)\n",
    "#     y_test = df_t['class_num'].values\n",
    "#     a = accuracy_score(y_test, km.predict(X_test))\n",
    "#     exactitudes.append(a)\n",
    "#     proporciones.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ent_red, df_pru_red = splitDataFrames(df_train, df_test, N, N_TEST, proporcion_positiva=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([vectorizeImage(file) for file in df_ent_red['path_redimensionada'].values])\n",
    "y_train = df_ent_red['class_num'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([vectorizeImage(file) for file in df_pru_red['path_redimensionada'].values])\n",
    "y_test = df_pru_red['class_num'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "# Cargar un conjunto de datos de ejemplo\n",
    "\n",
    "# Definir el tamaño del lote\n",
    "batch_size = 100\n",
    "\n",
    "# Inicializar IncrementalPCA con el número de componentes deseados\n",
    "n_components = 20\n",
    "ipca = IncrementalPCA(n_components=n_components)\n",
    "\n",
    "# Número total de muestras\n",
    "n_samples = X_train.shape[0]\n",
    "\n",
    "# Ajustar el modelo por lotes\n",
    "for i in range(0, n_samples, batch_size):\n",
    "    end = i + batch_size\n",
    "    if end > n_samples:\n",
    "        end = n_samples\n",
    "    ipca.partial_fit(X_train[i:end])\n",
    "\n",
    "# Transformar los datos completos utilizando el modelo ajustado\n",
    "X_transformed = ipca.transform(X_train)\n",
    "\n",
    "# Mostrar la proporción de varianza explicada por cada componente\n",
    "explained_variance_ratio = ipca.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Graficar la varianza acumulada+\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, n_components + 1), cumulative_variance, marker='o', linestyle='--')\n",
    "plt.title('Varianza Acumulada por Componentes IncrementalPCA')\n",
    "plt.xlabel('Número de Componentes')\n",
    "plt.ylabel('Varianza Acumulada')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "km = KMeans(n_clusters=2)\n",
    "km.fit(X_transformed)\n",
    "y_pred_test = km.predict(ipca.transform(X_test))\n",
    "a = accuracy_score(y_test, y_pred_test)\n",
    "print('Accuracy:', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matriz_confusion = confusion_matrix(y_test, y_pred_test)\n",
    "print(matriz_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|proporcion | exactitud|\n",
    "|-----------|----------|\n",
    "|0.5|0.693|\n",
    "|0.1|0.602|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
